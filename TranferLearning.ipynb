{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'albumentations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-43d5ad6f0ffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0malbumentations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'albumentations'"
     ]
    }
   ],
   "source": [
    "import cv2,sys, copy, scipy\n",
    "import torch\n",
    "import fiona, rasterio\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision \n",
    "import torchvision.models as models\n",
    "import albumentations as A\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from shapely import geometry\n",
    "from rasterio.mask import mask \n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from extractor_helper import extractor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "## for reprodusability\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprosseing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-48-2809dfca001b>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-2809dfca001b>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    return X, y\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class mydata(Dataset):\n",
    "    def __init__(self, data, mode='train'):\n",
    "        self.data = data\n",
    "        self.mode = model\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.tensor(self.data[idx][0]).permute(2,0,1).float()\n",
    "        y = torch.tensor(self.data[idx][1])\n",
    "        if self.model == 'train':\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTER_NEAREST – a nearest-neighbor interpolation.\n",
    "# INTER_LINEAR – a bilinear interpolation (used by default)\n",
    "# INTER_AREA – resampling using pixel area relation. ...\n",
    "# INTER_CUBIC – a bicubic interpolation over 4×4 pixel neighborhood.\n",
    "# INTER_LANCZOS4 – a Lanczos interpolation over 8×8 pixel neighborhood.\n",
    "\n",
    "def processing(patchsize = 3, interporlation = cv2.INTER_LANCZOS4, size = (224,224)):\n",
    "    \n",
    "    test2_img = rasterio.open(\"data/test2/pp_2_sat_modified.tif\")\n",
    "    test2_points = fiona.open(\"data/test2/points_2_modified_Copy.shp\", \"r\")\n",
    "    test3_img = rasterio.open(\"data/test3/pp_3_sat_modified.tif\")\n",
    "    test3_points = fiona.open(\"data/test3/targets_Copy.shp\", \"r\")\n",
    "    test4_img = rasterio.open(\"data/test4/pp_4_sat_modified_spline.tif\")\n",
    "    test4_points = fiona.open(\"data/test4/modified_points_Copy.shp\", \"r\")\n",
    "    \n",
    "    patch2, coordinates2, labels2 = extractor(test2_img,test2_points, size=patchsize, normalize=True, labeling=True)\n",
    "    patch3, coordinates3, labels3 = extractor(test3_img,test3_points, size=patchsize, normalize=True, labeling=True)\n",
    "    patch4, coordinates4, labels4 = extractor(test4_img,test4_points, size=patchsize, normalize=True, labeling=True)\n",
    "    \n",
    "    patch2 = [[cv2.resize(i,size,interpolation=interporlation), l] for i,l in zip(patch2, labels2)]\n",
    "    patch3 = [[cv2.resize(i,size,interpolation=interporlation), l] for i,l in zip(patch3, labels3)]\n",
    "    patch4 = [[cv2.resize(i,size,interpolation=interporlation), l] for i,l in zip(patch4, labels4)]\n",
    "    data = list(patch2 + patch3 + patch4)\n",
    "    \n",
    "    zero = [i for i in data if i[1] == 0]\n",
    "    one = [i for i in data if i[1] == 1.0]\n",
    "    two = [i for i in data if i[1] == 2.0]\n",
    "    three = [i for i in data if i[1] == 3.0]\n",
    "    \n",
    "    data =  two + zero[:48//3] + one[:48//3] + three[:48//3]\n",
    "    \n",
    "    for j, i in enumerate(data):\n",
    "        if i[1] == 2.0:\n",
    "            data[j][1] = 0\n",
    "        else:\n",
    "            data[j][1] = 1\n",
    "            \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaders(data, valsize=150, bsize=30):\n",
    "    \n",
    "    val_idx = list(np.random.randint(0,len(data), valsize))\n",
    "    train_idx = list(set(list(range(len(data)))) - set(val_idx))\n",
    "    trainloader = DataLoader(mydata(data[train_idx]), batch_size=bsize,\n",
    "                             shuffle=True, num_workers=8, pin_memory=True )\n",
    "    testloader  = DataLoader(mydata(data[val_idx]), batch_size=bsize,\n",
    "                             num_workers=8, pin_memory=True )\n",
    "    \n",
    "    return (train_idx, val_idx), trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoches, criterion, optimizer, trainloader, testloader, device, exp_name=None, scheduler=None):\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    if exp_name:\n",
    "        writer = SummaryWriter('./logs_weeklearns/{}'.format(exp_name))\n",
    "    else:\n",
    "        writer = SummaryWriter('./logs_weeklearns/{}'.format('single_ep'))\n",
    "        \n",
    "    bestval = {'bestvalacc': 0 , 'epoch': None, 'trainacc@Bval': None, 'iter':0}\n",
    "    for e in (range(1, epoches+1)):\n",
    "        \n",
    "        model.train()\n",
    "        meanloss = {'counter':0, 'correct':0, 'total':0}\n",
    "        for X, y in (trainloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            bestval['iter'] +=1\n",
    "            meanloss['total'] += len(y)\n",
    "            meanloss['correct'] += (torch.argmax(pred, dim=1) == y).sum().item()\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), global_step=bestval['iter'])\n",
    "            \n",
    "        writer.add_scalar(\"train_epoch_Accuracy\", meanloss['correct']/len(trainloader.dataset), global_step=e)\n",
    "        print('Epoch:{} |train_accuracy:{}'.format(e, meanloss['correct']/meanloss['total']))\n",
    "        model.eval()\n",
    "        meanlossval = {'loss':0, 'counter':0, 'correct':0,'total':0}\n",
    "        for X, y in testloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            meanlossval['loss'] += criterion(pred, y).item()\n",
    "            meanlossval['total'] += len(y)\n",
    "            meanlossval['correct'] += (torch.argmax(pred, dim=1) == y).sum().item()\n",
    "            \n",
    "        writer.add_scalar(\"test_epoch_Accuracy\", meanlossval['correct']/len(testloader.dataset), global_step=e)\n",
    "        print('Epoch:{} |test_accuracy:{}'.format(e, meanlossval['correct']/meanlossval['total']))\n",
    "        print('--'*50)\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "            \n",
    "        if meanlossval['correct']/meanlossval['total'] > bestval['bestvalacc']:\n",
    "            bestval['bestvalacc'] = meanlossval['correct']/meanlossval['total']\n",
    "            bestval['trainacc@Bval'] = meanloss['correct']/meanloss['total']\n",
    "            bestval['epoch'] = e\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "    print(bestval)\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot():\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(data[3][0][...,[2,3,5]]*10)\n",
    "    plt.title('rgb view of a tree')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.hist([i[1] for i in data[split_idx[0]]], bins=5);\n",
    "    plt.title('class distribution: train')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.hist([i[1] for i in data[split_idx[1]]], bins=5);\n",
    "    plt.title('class distribution: test');\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsdr/.local/lib/python3.6/site-packages/ipykernel_launcher.py:38: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "patchsize = 3 ### size of a patch \n",
    "interporlation = cv2.INTER_LANCZOS4 ### interpolation for resizing image \n",
    "\n",
    "data = processing(patchsize=patchsize, \n",
    "                  interporlation=interporlation,)\n",
    "batchsize = 10\n",
    "valsize = int(len(data) * .15) ## validation size 15 percent\n",
    "\n",
    "split_idx, trainloader, testloader = loaders(data, valsize=valsize, bsize=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-15T23:27:36.598813{'lr': 0.003, 'epoches': 15, 'weight_dec': 0.0005, 'batch_size': 10, 'interporlation': 4, 'patch_size': 3, 'scheduler': None}\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "####### SELECT MODELS and freeze weights\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.requires_grad_(False);\n",
    "\n",
    "###### CHANGE Classifier \n",
    "model.conv1 = nn.Conv2d(8,64, kernel_size=(7,7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model.fc = nn.Linear(512,2)\n",
    "                         \n",
    "\n",
    "model.to(device)\n",
    "epoches = 15\n",
    "learning_rate = 3e-3\n",
    "w_decay = 5e-4\n",
    "\n",
    "parameters  = [{'params': model.conv1.parameters(),'lr': 1e-4},\n",
    "               {'params': model.fc.parameters()}]\n",
    "\n",
    "# class_weights = torch.tensor(class_weights, dtype = torch.float32).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam( parameters,\n",
    "                              lr=learning_rate,\n",
    "                              weight_decay=w_decay)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [7,10,13], gamma=0.1)\n",
    "scheduler = None\n",
    "\n",
    "params = {'lr':learning_rate,\n",
    "          'epoches': epoches,\n",
    "          'weight_dec': w_decay,\n",
    "          'batch_size': batchsize,\n",
    "          'interporlation': interporlation,\n",
    "          'patch_size': patchsize,\n",
    "          'scheduler': scheduler}\n",
    "\n",
    "exp_name = datetime.now().isoformat() + str(params)\n",
    "print(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 |train_accuracy:0.44871794871794873\n",
      "Epoch:1 |test_accuracy:0.6153846153846154\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:2 |train_accuracy:0.6025641025641025\n",
      "Epoch:2 |test_accuracy:0.7692307692307693\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:3 |train_accuracy:0.717948717948718\n",
      "Epoch:3 |test_accuracy:0.6153846153846154\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:4 |train_accuracy:0.7564102564102564\n",
      "Epoch:4 |test_accuracy:0.6153846153846154\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:5 |train_accuracy:0.8076923076923077\n",
      "Epoch:5 |test_accuracy:0.6923076923076923\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:6 |train_accuracy:0.7307692307692307\n",
      "Epoch:6 |test_accuracy:0.6153846153846154\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:7 |train_accuracy:0.782051282051282\n",
      "Epoch:7 |test_accuracy:0.6153846153846154\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:8 |train_accuracy:0.8717948717948718\n",
      "Epoch:8 |test_accuracy:0.6153846153846154\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:9 |train_accuracy:0.7692307692307693\n",
      "Epoch:9 |test_accuracy:0.6923076923076923\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:10 |train_accuracy:0.7692307692307693\n",
      "Epoch:10 |test_accuracy:0.6153846153846154\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:11 |train_accuracy:0.717948717948718\n",
      "Epoch:11 |test_accuracy:1.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:12 |train_accuracy:0.7307692307692307\n",
      "Epoch:12 |test_accuracy:0.5384615384615384\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:13 |train_accuracy:0.7692307692307693\n",
      "Epoch:13 |test_accuracy:0.8461538461538461\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:14 |train_accuracy:0.8589743589743589\n",
      "Epoch:14 |test_accuracy:0.9230769230769231\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:15 |train_accuracy:0.9102564102564102\n",
      "Epoch:15 |test_accuracy:0.8461538461538461\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'bestvalacc': 1.0, 'epoch': 11, 'trainacc@Bval': 0.717948717948718, 'iter': 120}\n"
     ]
    }
   ],
   "source": [
    "best_model = train(model, epoches, criterion, optimizer, trainloader, testloader, device, exp_name, scheduler )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred,y_true = [],[]\n",
    "    for b, y in testloader:\n",
    "        b = b.to(device)\n",
    "        y_pred.extend(torch.argmax(best_model(b), dim=1).cpu().numpy())\n",
    "        y_true.extend(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[65,  9,  3],\n",
       "       [ 7, 34,  6],\n",
       "       [ 1,  0, 20]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(best_model.state_dict(),'./best_ensumble/resnet50_82.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20186), started 0:03:39 ago. (Use '!kill 20186' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-61ec694fa502853e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-61ec694fa502853e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "logs_base_dir = \"./logs_weeklearns/\"\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in best_model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_parameters = best_model.parameters()\n",
    "\n",
    "learning_rate = 0\n",
    "optimizer = torch.optim.Adam(\n",
    "    trainable_parameters, lr=learning_rate, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 |train_accuracy:0.828125\n",
      "Epoch:1 |test_accuracy:0.8137931034482758\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'bestvalacc': 0.8137931034482758, 'epoch': 1, 'trainacc@Bval': 0.828125, 'iter': 28}\n"
     ]
    }
   ],
   "source": [
    "best_model = train(best_model, 1, criterion, optimizer, trainloader, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_learning_rate(optimizer, new_learning_rate):\n",
    "    \"\"\"Set learning rates of the optimizer to `new_learning_rate`.\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = new_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "set_learning_rate(optimizer, learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,6 ,gamma=0.1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 |train_accuracy:0.8221153846153846\n",
      "Epoch:1 |test_accuracy:0.46206896551724136\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:2 |train_accuracy:0.8629807692307693\n",
      "Epoch:2 |test_accuracy:0.7517241379310344\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:3 |train_accuracy:0.875\n",
      "Epoch:3 |test_accuracy:0.6620689655172414\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:4 |train_accuracy:0.9026442307692307\n",
      "Epoch:4 |test_accuracy:0.6896551724137931\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:5 |train_accuracy:0.9302884615384616\n",
      "Epoch:5 |test_accuracy:0.7517241379310344\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:6 |train_accuracy:0.9471153846153846\n",
      "Epoch:6 |test_accuracy:0.7793103448275862\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:7 |train_accuracy:0.9663461538461539\n",
      "Epoch:7 |test_accuracy:0.7793103448275862\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:8 |train_accuracy:0.9795673076923077\n",
      "Epoch:8 |test_accuracy:0.8206896551724138\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:9 |train_accuracy:0.9867788461538461\n",
      "Epoch:9 |test_accuracy:0.8068965517241379\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:10 |train_accuracy:0.9879807692307693\n",
      "Epoch:10 |test_accuracy:0.7793103448275862\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:11 |train_accuracy:0.9831730769230769\n",
      "Epoch:11 |test_accuracy:0.7793103448275862\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:12 |train_accuracy:0.9915865384615384\n",
      "Epoch:12 |test_accuracy:0.8068965517241379\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:13 |train_accuracy:0.9855769230769231\n",
      "Epoch:13 |test_accuracy:0.7793103448275862\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:14 |train_accuracy:0.984375\n",
      "Epoch:14 |test_accuracy:0.7931034482758621\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:15 |train_accuracy:0.9975961538461539\n",
      "Epoch:15 |test_accuracy:0.7931034482758621\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:16 |train_accuracy:0.9795673076923077\n",
      "Epoch:16 |test_accuracy:0.7862068965517242\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:17 |train_accuracy:0.9891826923076923\n",
      "Epoch:17 |test_accuracy:0.7793103448275862\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:18 |train_accuracy:0.9939903846153846\n",
      "Epoch:18 |test_accuracy:0.7862068965517242\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:19 |train_accuracy:0.9927884615384616\n",
      "Epoch:19 |test_accuracy:0.7931034482758621\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch:20 |train_accuracy:0.9867788461538461\n",
      "Epoch:20 |test_accuracy:0.7862068965517242\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'bestvalacc': 0.8206896551724138, 'epoch': 8, 'trainacc@Bval': 0.9795673076923077, 'iter': 560}\n"
     ]
    }
   ],
   "source": [
    "best_model = train(best_model, 20, criterion, optimizer, trainloader, testloader, device, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(best_model.state_dict(),'./best_ensumble/wide_resnet50_80.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
